#include<iostream>
#include<pthread.h>

//常见的死锁

//1.上锁之后没有解锁
//
//解决办法：像申请内存一样 记住上锁后一定解锁


//2.在一个临界区重复上一把锁 这样的话第二次上锁要等到第一次的锁解锁才能执行 但是不继续执行的话
//又走不到第一把锁解锁的代码 这样就造成了死锁
//
//解决办法：不要在一个临界区上同一把锁 操作系统也可以检测这种死锁当上同一把锁时发错错误信号
//这种死锁比较好处理 


//3.当一个场景有了多把锁的时候会变得有趣起来 假如有两个cpu核心0号执行fun1使用公共变量a、b 
//1号使用fun2也使用用a、b 所以a、b产生竞争是要上锁的 当fun1获取先获取a的锁 同时fun2获取
//了b的锁 fun1用完了a之后要使用b的锁 fun2这时也运行完了要使用a的锁 这样就造成了一个现象
//fun1在等fun2释放b的锁 fun2在等fun1释放a的锁 造成了互相等待 这种死锁又叫死亡拥抱 死亡拥抱
//很多时候是检测不到的比较难处理
//
//解决办法：当全局有多把锁时我们把锁排序 必须按照锁的顺序严格的获取锁 这样就可以解决死亡拥抱
//因为上锁有了顺序之后不会产生我们上面描述的场景 假如锁的顺序是a、b 当fun1获取a的锁时 fun2
//不会在获取b的锁了有了排序规则后它会等待fun1释放a的锁在获取a的锁 当然这也是有代价的 我们设计
//程序的原则是 保持代码的抽象 当模块1中的方法f1使用了模块2中的方法f2时模块1就必须要知道模块2
//中方法f2使用了哪些锁这样才可以给锁排序 这就意味着模块2中的锁对模块1是可见的 这就违背了抽象
//原则 理想状态下模块1是完全不知道模块2是如何实现的 但是不幸的是模块2是要把锁透漏给模块1的
//所以随着项目的变大模块化也该更加复杂了


//凡事有利有弊 锁也一样 虽然使用锁让程序可以并行运行获得高性能但是锁也会限制并行 如果只有一个
//大锁的话那么进程一次只能被一个cpu运行 所以如果想增加性能的话就需要对数据结构和锁进行拆分
